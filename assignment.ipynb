{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the complexity of analyzing visual data like protest pageantry, and the desire to avoid overly simplistic models, a combination of supervised and unsupervised machine learning techniques would likely be most relevant.  Specifically, convolutional neural networks (CNNs), a form of deep learning, would be suitable for image feature extraction.  Since the researcher has captions describing the protest's topic, this labeled data could be used in a supervised learning approach to train a CNN to recognize visual cues associated with different protest themes.  However, the researcher might also want to discover *unforeseen* visual similarities across protests, even those with different stated aims.  For this, unsupervised learning methods like clustering algorithms (e.g., k-means) could be applied to the extracted image features to group protests based on visual similarity, potentially revealing interesting patterns.  The captions could then be used *post hoc* to understand the themes of these visually-derived clusters.  There's ambiguity in how precisely the captions will be used â€“ will they be the *sole* basis for supervised learning, or will they supplement other labeled data?  Also, the researcher could use transfer learning, leveraging pre-trained CNNs on large image datasets, to fine-tune the model for this specific task, potentially reducing the need for extensive labeled data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the sample data\n",
    "data = pd.read_csv('formative_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "\n",
    "X = data[['x1', 'x2', 'x3', 'x4', 'x5']]\n",
    "y = data['outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I will create a function to test many different model specifications for a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for transformations\n",
    "\n",
    "def transform_data(X, spec):\n",
    "    \"\"\"\n",
    "    Transforms the DataFrame X according to a spec string or dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : pd.DataFrame\n",
    "        The original feature DataFrame.\n",
    "    spec : str\n",
    "        A label describing the transformation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_transformed : pd.DataFrame\n",
    "        A new DataFrame of transformed features.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy so we don't modify the original\n",
    "    X_new = X.copy()\n",
    "\n",
    "    if spec == 'baseline':\n",
    "        # Return X as is\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'only_x1':\n",
    "        # Return a DataFrame with only x1\n",
    "        return X[['x1']].copy()\n",
    "\n",
    "    elif spec == 'only_x2':\n",
    "        return X[['x2']].copy()\n",
    "\n",
    "    elif spec == 'only_x3':\n",
    "        return X[['x3']].copy()\n",
    "\n",
    "    elif spec == 'only_x4':\n",
    "        return X[['x4']].copy()\n",
    "\n",
    "    elif spec == 'only_x5':\n",
    "        return X[['x5']].copy()\n",
    "\n",
    "    elif spec == 'x1_x2_only':\n",
    "        return X[['x1','x2']].copy()\n",
    "\n",
    "    elif spec == 'x1_x2_x3_only':\n",
    "        return X[['x1','x2','x3']].copy()\n",
    "\n",
    "    elif spec == 'x1_x2_x3_x4_only':\n",
    "        return X[['x1','x2','x3','x4']].copy()\n",
    "\n",
    "    elif spec == 'x1_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x2_squared':\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x5_squared':\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x5_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x2_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x2_and_x5_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x2_and_x3_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        X_new['x3_squared'] = X_new['x3'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x2_and_x3_and_x4_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        X_new['x3_squared'] = X_new['x3'] ** 2\n",
    "        X_new['x4_squared'] = X_new['x4'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_and_x2_and_x3_and_x4_and_x5_squared':\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x2_squared'] = X_new['x2'] ** 2\n",
    "        X_new['x3_squared'] = X_new['x3'] ** 2\n",
    "        X_new['x4_squared'] = X_new['x4'] ** 2\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_x2_interaction':\n",
    "        X_new['x1_x2'] = X_new['x1'] * X_new['x2']\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x4_x5_interaction':\n",
    "        X_new['x4_x5'] = X_new['x4'] * X_new['x5']\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'x1_squared_interaction':\n",
    "        # Combine squaring x1 and adding x1*x2\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x1_x2']      = X_new['x1'] * X_new['x2']\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'log_x1':\n",
    "        # Handle negatives or zero by shifting\n",
    "        X_new['log_x1'] = np.log(np.abs(X_new['x1']) + 1)\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'log_x2':\n",
    "        X_new['log_x2'] = np.log(np.abs(X_new['x2']) + 1)\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'log_all':\n",
    "        # Log transform all features that can be safely logged\n",
    "        # We do abs(value) + 1 for each\n",
    "        for col in X_new.columns:\n",
    "            X_new[f'log_{col}'] = np.log(np.abs(X_new[col]) + 1)\n",
    "        return X_new\n",
    "\n",
    "    elif spec == 'polynomial_degree_2':\n",
    "        # Use PolynomialFeatures from sklearn\n",
    "        # This will create 1, x1, x2, x3, x4, x5, plus cross terms and squares\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        arr = poly.fit_transform(X_new)\n",
    "        col_names = poly.get_feature_names_out(X_new.columns)\n",
    "        return pd.DataFrame(arr, columns=col_names)\n",
    "\n",
    "    elif spec == 'polynomial_degree_3':\n",
    "        # Similarly for cubic features\n",
    "        poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "        arr = poly.fit_transform(X_new)\n",
    "        col_names = poly.get_feature_names_out(X_new.columns)\n",
    "        return pd.DataFrame(arr, columns=col_names)\n",
    "\n",
    "\n",
    "    # All features + squares + all pairwise interactions\n",
    "    elif spec == 'all_features_squares_interactions':\n",
    "        # For every feature, create a squared column\n",
    "        for col in X_new.columns:\n",
    "            X_new[f'{col}_squared'] = X_new[col] ** 2\n",
    "        # For every pair, create an interaction column\n",
    "        cols = X_new.columns\n",
    "        for i in range(len(cols)):\n",
    "            for j in range(i+1, len(cols)):\n",
    "                X_new[f'{cols[i]}_x_{cols[j]}'] = X_new[cols[i]] * X_new[cols[j]]\n",
    "        return X_new\n",
    "\n",
    "    # Only x1 and x5 + squares + interaction\n",
    "    elif spec == 'x1_and_x5_squares_interaction':\n",
    "        X_new = X[['x1','x5']].copy()\n",
    "        X_new['x1_squared'] = X_new['x1'] ** 2\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        X_new['x1_x5'] = X_new['x1'] * X_new['x5']\n",
    "        return X_new\n",
    "\n",
    "    # Polynomial degree 2 ignoring x3\n",
    "    elif spec == 'poly_deg2_ignore_x3':\n",
    "        X_subset = X[['x1','x2','x4','x5']].copy()\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        arr = poly.fit_transform(X_subset)\n",
    "        col_names = poly.get_feature_names_out(X_subset.columns)\n",
    "        return pd.DataFrame(arr, columns=col_names)\n",
    "\n",
    "    # Logs + squares for x1, x5\n",
    "    elif spec == 'log_x1_and_x5_squared':\n",
    "        X_new = X.copy()\n",
    "        X_new['log_x1'] = np.log(np.abs(X_new['x1']) + 1)\n",
    "        X_new['x5_squared'] = X_new['x5'] ** 2\n",
    "        return X_new\n",
    "\n",
    "    # Cubic for x1 and x5 only\n",
    "    elif spec == 'cubic_x1_and_x5_only':\n",
    "        X_subset = X[['x1','x5']].copy()\n",
    "        poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "        arr = poly.fit_transform(X_subset)\n",
    "        col_names = poly.get_feature_names_out(X_subset.columns)\n",
    "        return pd.DataFrame(arr, columns=col_names)\n",
    "\n",
    "    # Polynomial on x5 plus log x1\n",
    "    elif spec == 'poly_x5_plus_log_x1':\n",
    "        # Handle infinities by turning them into NaN\n",
    "        X_clean = X.replace([np.inf, -np.inf], np.nan).copy()\n",
    "\n",
    "        # Drop any rows where x1 or x5 is NaN\n",
    "        # (Or you could impute if you prefer)\n",
    "        X_clean = X_clean.dropna(subset=['x1','x5'])\n",
    "\n",
    "        # Keep track of the index that remains\n",
    "        idx = X_clean.index\n",
    "\n",
    "        # Polynomial expansion for x5\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        arr = poly.fit_transform(X_clean[['x5']])\n",
    "        col_names = poly.get_feature_names_out(['x5'])\n",
    "\n",
    "        X_poly = pd.DataFrame(arr, columns=col_names, index=idx)\n",
    "\n",
    "        # Add log_x1\n",
    "        X_poly['log_x1'] = np.log(np.abs(X_clean['x1']) + 1)\n",
    "\n",
    "        # (Optionally) add other columns\n",
    "        X_poly[['x2','x3','x4']] = X_clean[['x2','x3','x4']]\n",
    "\n",
    "        return X_poly\n",
    "\n",
    "\n",
    "    # Interactions among x2, x4, x5 only\n",
    "    elif spec == 'selective_interactions_x2_x4_x5':\n",
    "        X_new['x2_x4'] = X_new['x2'] * X_new['x4']\n",
    "        X_new['x2_x5'] = X_new['x2'] * X_new['x5']\n",
    "        X_new['x4_x5'] = X_new['x4'] * X_new['x5']\n",
    "        return X_new\n",
    "\n",
    "    # Binning x4\n",
    "    elif spec == 'x4_binned':\n",
    "        # Example bins for x4 -> adjust to your data\n",
    "        bins = [-np.inf, 0, 2, np.inf]\n",
    "        labels = ['low','medium','high']\n",
    "        X_new['x4_binned'] = pd.cut(X_new['x4'], bins=bins, labels=labels)\n",
    "        X_new = pd.get_dummies(X_new, columns=['x4_binned'], drop_first=True)\n",
    "        return X_new\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown specification: {spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now I will test each specification and keep the one with the highest score on th test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spec: all_features_squares_interactions RÂ²: 0.9712  MSE: 2.4884\n",
      "Spec: poly_x5_plus_log_x1            RÂ²: 0.8841  MSE: 10.0054\n",
      "Spec: log_x1_and_x5_squared          RÂ²: 0.8837  MSE: 10.0369\n",
      "Spec: x1_and_x2_and_x3_and_x4_and_x5_squared RÂ²: 0.7965  MSE: 17.5642\n",
      "Spec: x1_and_x5_squared              RÂ²: 0.7963  MSE: 17.5849\n",
      "Spec: x1_and_x2_and_x5_squared       RÂ²: 0.7961  MSE: 17.6004\n",
      "Spec: x1_and_x2_and_x3_and_x4_squared RÂ²: 0.7957  MSE: 17.6338\n",
      "Spec: x1_squared                     RÂ²: 0.7952  MSE: 17.6760\n",
      "Spec: x1_and_x2_squared              RÂ²: 0.7947  MSE: 17.7233\n",
      "Spec: x1_and_x2_and_x3_squared       RÂ²: 0.7947  MSE: 17.7233\n",
      "Spec: x5_squared                     RÂ²: 0.7938  MSE: 17.7986\n",
      "Spec: x1_squared_interaction         RÂ²: 0.7932  MSE: 17.8472\n",
      "Spec: polynomial_degree_3            RÂ²: 0.7685  MSE: 19.9872\n",
      "Spec: polynomial_degree_2            RÂ²: 0.7682  MSE: 20.0056\n",
      "Spec: poly_deg2_ignore_x3            RÂ²: 0.7622  MSE: 20.5245\n",
      "Spec: x1_and_x5_squares_interaction  RÂ²: 0.6962  MSE: 26.2218\n",
      "Spec: cubic_x1_and_x5_only           RÂ²: 0.6344  MSE: 31.5562\n",
      "Spec: log_all                        RÂ²: 0.4737  MSE: 45.4307\n",
      "Spec: log_x1                         RÂ²: 0.3599  MSE: 55.2558\n",
      "Spec: only_x3                        RÂ²: 0.0570  MSE: 81.3988\n",
      "Spec: only_x4                        RÂ²: 0.0500  MSE: 82.0082\n",
      "Spec: only_x2                        RÂ²: -0.0010  MSE: 86.4037\n",
      "Spec: x1_x2_x3_x4_only               RÂ²: -0.0373  MSE: 89.5433\n",
      "Spec: baseline                       RÂ²: -0.0381  MSE: 89.6097\n",
      "Spec: x1_x2_x3_only                  RÂ²: -0.0413  MSE: 89.8832\n",
      "Spec: x1_x2_interaction              RÂ²: -0.0414  MSE: 89.8913\n",
      "Spec: x2_squared                     RÂ²: -0.0457  MSE: 90.2630\n",
      "Spec: x4_binned                      RÂ²: -0.0457  MSE: 90.2684\n",
      "Spec: log_x2                         RÂ²: -0.0464  MSE: 90.3278\n",
      "Spec: x4_x5_interaction              RÂ²: -0.0773  MSE: 92.9967\n",
      "Spec: only_x5                        RÂ²: -0.0951  MSE: 94.5285\n",
      "Spec: only_x1                        RÂ²: -0.0974  MSE: 94.7308\n",
      "Spec: x1_x2_only                     RÂ²: -0.0975  MSE: 94.7379\n",
      "Spec: selective_interactions_x2_x4_x5 RÂ²: -0.1086  MSE: 95.6918\n",
      "\n",
      "Best specification: all_features_squares_interactions\n",
      "Best RÂ²: 0.9711732037580008\n",
      "Best MSE: 2.4883556640485103\n"
     ]
    }
   ],
   "source": [
    "# Define many specifications\n",
    "\n",
    "specs = [\n",
    "    'baseline',\n",
    "    'only_x1',\n",
    "    'only_x2',\n",
    "    'only_x3',\n",
    "    'only_x4',\n",
    "    'only_x5',\n",
    "    'x1_x2_only',\n",
    "    'x1_x2_x3_only',\n",
    "    'x1_x2_x3_x4_only',\n",
    "    'x1_squared',\n",
    "    'x2_squared',\n",
    "    'x5_squared',\n",
    "    'x1_and_x5_squared',\n",
    "    'x1_and_x2_squared',\n",
    "    'x1_and_x2_and_x5_squared',\n",
    "    'x1_and_x2_and_x3_squared',\n",
    "    'x1_and_x2_and_x3_and_x4_squared',\n",
    "    'x1_and_x2_and_x3_and_x4_and_x5_squared',\n",
    "    'x1_x2_interaction',\n",
    "    'x4_x5_interaction',\n",
    "    'x1_squared_interaction',\n",
    "    'log_x1',\n",
    "    'log_x2',\n",
    "    'log_all',\n",
    "    'polynomial_degree_2',\n",
    "    'polynomial_degree_3',\n",
    "    'all_features_squares_interactions',\n",
    "    'x1_and_x5_squares_interaction',\n",
    "    'poly_deg2_ignore_x3',\n",
    "    'log_x1_and_x5_squared',\n",
    "    'cubic_x1_and_x5_only',\n",
    "    'poly_x5_plus_log_x1',\n",
    "    'selective_interactions_x2_x4_x5',\n",
    "    'x4_binned'\n",
    "]\n",
    "\n",
    "# 5) Train and evaluate each spec\n",
    "\n",
    "results = []\n",
    "\n",
    "for spec in specs:\n",
    "    # Transform training and test data\n",
    "    X_train_t = transform_data(X_train, spec)\n",
    "    X_test_t  = transform_data(X_test, spec)\n",
    "\n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_t, y_train)\n",
    "\n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_t)\n",
    "\n",
    "    # Calculate RÂ² and MSE\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    # Store (spec, r2, mse)\n",
    "    results.append((spec, r2, mse))\n",
    "\n",
    "# Sort results by RÂ² descending\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print out specs, RÂ², and MSE\n",
    "for spec, r2_val, mse_val in results:\n",
    "    print(f\"Spec: {spec:30s} RÂ²: {r2_val:.4f}  MSE: {mse_val:.4f}\")\n",
    "\n",
    "best_spec, best_r2, best_mse = results[0]\n",
    "print(\"\\nBest specification:\", best_spec)\n",
    "print(\"Best RÂ²:\", best_r2)\n",
    "print(\"Best MSE:\", best_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best model is 'all_features_squares_interactions' with a RÂ² of 97%. Let's fit this model and analyze its coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Feature  Coefficient\n",
      "             x1_squared     8.111226\n",
      "             x2_squared     8.044411\n",
      "        x1_x_x2_squared     4.133054\n",
      "                     x1     3.317359\n",
      "                x2_x_x3     2.245588\n",
      "        x2_x_x3_squared     2.245588\n",
      "             x3_squared     1.795218\n",
      "        x3_x_x3_squared     1.795218\n",
      "                     x3     1.795218\n",
      "        x4_x_x2_squared     1.298972\n",
      "                x1_x_x5     1.077665\n",
      "                x1_x_x4     0.713558\n",
      "x1_squared_x_x2_squared     0.679454\n",
      "x1_squared_x_x3_squared     0.507564\n",
      "        x3_x_x1_squared     0.507564\n",
      "        x5_x_x2_squared     0.312359\n",
      "                     x5     0.277009\n",
      "        x2_x_x4_squared     0.236092\n",
      "                     x4     0.171768\n",
      "                x4_x_x5     0.057962\n",
      "             x5_squared     0.034288\n",
      "        x1_x_x4_squared     0.032483\n",
      "x1_squared_x_x5_squared     0.006601\n",
      "        x4_x_x4_squared     0.005040\n",
      "        x5_x_x4_squared     0.002527\n",
      "x3_squared_x_x4_squared     0.002464\n",
      "        x3_x_x4_squared     0.002464\n",
      "        x2_x_x5_squared     0.001668\n",
      "        x4_x_x5_squared     0.000880\n",
      "x4_squared_x_x5_squared     0.000052\n",
      "x3_squared_x_x5_squared    -0.004075\n",
      "        x3_x_x5_squared    -0.004075\n",
      "x2_squared_x_x5_squared    -0.004558\n",
      "x1_squared_x_x4_squared    -0.010061\n",
      "             x4_squared    -0.010395\n",
      "        x5_x_x5_squared    -0.041476\n",
      "        x2_x_x1_squared    -0.048625\n",
      "        x4_x_x1_squared    -0.082624\n",
      "                x3_x_x5    -0.146048\n",
      "        x5_x_x3_squared    -0.146048\n",
      "x2_squared_x_x4_squared    -0.181626\n",
      "        x4_x_x3_squared    -0.207875\n",
      "                x3_x_x4    -0.207875\n",
      "                x2_x_x5    -0.395717\n",
      "                x2_x_x4    -1.135356\n",
      "        x1_x_x5_squared    -1.462084\n",
      "                x1_x_x3    -1.832480\n",
      "        x1_x_x3_squared    -1.832480\n",
      "        x3_x_x2_squared    -2.884968\n",
      "x2_squared_x_x3_squared    -2.884968\n",
      "        x2_x_x2_squared    -3.221832\n",
      "                x1_x_x2    -5.140215\n",
      "                     x2    -5.614728\n",
      "        x5_x_x1_squared   -17.104797\n",
      "        x1_x_x1_squared   -66.345228\n",
      "\n",
      "Intercept: -0.06228481654693496\n"
     ]
    }
   ],
   "source": [
    "# 1) Transform the training data for the \"all_features_squares_interactions\" spec\n",
    "X_train_t = transform_data(X_train, 'all_features_squares_interactions')\n",
    "X_test_t  = transform_data(X_test,  'all_features_squares_interactions')\n",
    "\n",
    "# 2) Fit a linear regression model on that specification\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_t, y_train)\n",
    "\n",
    "# 3) Create a DataFrame listing each feature and its coefficient\n",
    "coeffs_df = pd.DataFrame({\n",
    "    'Feature': X_train_t.columns,\n",
    "    'Coefficient': model.coef_\n",
    "}).sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Print the coefficients table\n",
    "print(coeffs_df.to_string(index=False))\n",
    "\n",
    "# 4) Print the model intercept\n",
    "print(\"\\nIntercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Description**  \n",
    "The final modelâ€”labeled **`all_features_squares_interactions`**â€”is a linear regression model that uses:\n",
    "\n",
    "- **All Original Features** $x_1$,$x_2$,$x_3$,$x_4$,$x_5$ \n",
    "- **Squared Terms** $x_i^2$ for each feature $x_i$  \n",
    "- **All Pairwise Interactions** $x_i$ x $x_j$ for every pair of features $i, j$\n",
    "\n",
    "By including both squared terms and pairwise products, this model can capture a variety of **nonlinear relationships** that a standard linear model could miss. Essentially, itâ€™s a polynomial expansion of degree 2 across all five features.\n",
    "\n",
    "---\n",
    "\n",
    "**Notable Features**  \n",
    "- Because we generate many new columns (one for each square and each interaction), we end up with a **large set of features**.  \n",
    "- In practice, certain squared terms and interactions often dominateâ€”for instance, if $x_1$ or $x_5$ is particularly influential, you might see large positive or negative coefficients for $x_1^2$, $x_5^2$, or $x_1 \\times x_5$.  \n",
    "- You can inspect the coefficients table to see which derived features have **highest magnitude** coefficients (positively or negatively).\n",
    "\n",
    "---\n",
    "\n",
    "**Model Performance and Assessment**  \n",
    "- The best RÂ² on the test set is **0.971**, meaning the model explains about **97% of the variance** in the outcome on held-out data.  \n",
    "- The **Mean Squared Error (MSE)** is **2.488**, indicating (on average) how far off predictions are from true values (squared difference). A smaller MSE generally indicates better performance.  \n",
    "- These metrics (RÂ² and MSE) were obtained on a **test set** that was separated from the training data, providing a straightforward estimate of how well the model generalizes.  \n",
    "- An RÂ² of 0.97 suggests **very good fit** for the given dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
